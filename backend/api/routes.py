import time
from flask import Blueprint, jsonify, request
from backend.services.dextools_service import DEXToolsService
from backend.services.token_analyzer import TokenAnalyzer
from backend.services.performance_analyzer import performance_analyzer

api = Blueprint('api', __name__)
dextools = DEXToolsService()
analyzer = TokenAnalyzer()

@api.route('/hot-pools', methods=['GET'])
def get_hot_pools():
    """Get Solana hot pools - ALWAYS FRESH, NO CACHE"""
    try:
        limit = request.args.get('limit', 50, type=int)
        limit = min(max(limit, 1), 100)  # Between 1 and 100
        
        # Force fresh data - no cache
        pools = dextools.get_hot_pools(limit)
        print(f"üìä Raw pools received: {len(pools)}")
        print(f"üî• First pool: {pools[0].get('mainToken', {}).get('symbol') if pools else 'None'}")
        
        # Don't reverse - keep original ranking order
        # pools.reverse() # REMOVED - was causing wrong order
        
        # Add timestamp to show data freshness
        import datetime
        
        # Return raw data with success wrapper and no-cache headers
        response = jsonify({
            'success': True,
            'data': pools,
            'count': len(pools),
            'timestamp': datetime.datetime.now().isoformat(),
            'chain': 'solana'
        })
        
        # Add headers to prevent caching
        response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
        
        return response
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/token/<token_address>', methods=['GET'])
def get_token_analysis(token_address):
    """Get complete token analysis"""
    try:
        analysis = dextools.get_complete_token_analysis(token_address)
        
        # Transform data for frontend
        result = {
            'tokenAddress': token_address,
            'success': analysis['success'],
            'data': {
                'info': {
                    'name': 'N/A',
                    'symbol': 'N/A',
                    'decimals': 0,
                    'logo': '',
                    'description': '',
                    'createdAt': '',
                    'socialInfo': {}
                },
                'price': {
                    'current': 0,
                    'change24h': 0,
                    'change1h': 0,
                    'change6h': 0,
                    'price24hAgo': 0,
                    'price1hAgo': 0
                },
                'score': {
                    'total': 0,
                    'upvotes': 0,
                    'downvotes': 0
                },
                'metrics': {
                    'liquidity_usd': 0,
                    'volume_24h_usd': 0,
                    'volume_1h_usd': 0,
                    'volume_6h_usd': 0,
                    'mcap': 0,
                    'fdv': 0,
                    'circulating_supply': 0,
                    'total_supply': 0,
                    'holders_count': 0,
                    'transactions': 0,
                    'pool_address': '',
                    'dex_info': {}
                },
                'audit': {
                    'is_open_source': 'unknown',
                    'is_honeypot': 'unknown',
                    'is_mintable': 'unknown',
                    'is_proxy': 'unknown',
                    'slippage_modifiable': 'unknown',
                    'is_blacklisted': 'unknown',
                    'is_contract_renounced': 'unknown',
                    'is_potentially_scam': 'unknown',
                    'buy_tax': {'min': 0, 'max': 0, 'status': 'unknown'},
                    'sell_tax': {'min': 0, 'max': 0, 'status': 'unknown'},
                    'updated_at': ''
                },
                'tax_analysis': {
                    'buy_tax_info': {
                        'min_percent': 0,
                        'max_percent': 0,
                        'status': 'unknown',
                        'assessment': ''
                    },
                    'sell_tax_info': {
                        'min_percent': 0,
                        'max_percent': 0,
                        'status': 'unknown',
                        'assessment': ''
                    },
                    'overall_assessment': '',
                    'is_honeypot': 'unknown',
                    'slippage_modifiable': 'unknown',
                    'contract_renounced': 'unknown'
                }
            }
        }
        
        # Process token info
        if analysis['info'] and analysis['info'].get('statusCode') == 200:
            info_data = analysis['info'].get('data', {})
            result['data']['info'] = {
                'name': info_data.get('name', 'N/A'),
                'symbol': info_data.get('symbol', 'N/A'),
                'decimals': info_data.get('decimals', 0),
                'logo': info_data.get('logo', ''),
                'description': info_data.get('description', ''),
                'createdAt': info_data.get('creationTime', ''),
                'socialInfo': info_data.get('socialInfo', {})
            }
        
        # Process price info
        if analysis['price'] and analysis['price'].get('statusCode') == 200:
            price_data = analysis['price'].get('data', {})
            result['data']['price'] = {
                'current': price_data.get('price', 0),
                'change24h': price_data.get('variation24h', 0),
                'change1h': price_data.get('variation1h', 0),
                'change6h': price_data.get('variation6h', 0),
                'price24hAgo': price_data.get('price24h', 0),
                'price1hAgo': price_data.get('price1h', 0)
            }
        
        # Process score info
        if analysis['score'] and analysis['score'].get('statusCode') == 200:
            score_data = analysis['score'].get('data', {})
            dext_score = score_data.get('dextScore', {})
            votes = score_data.get('votes', {})
            
            result['data']['score'] = {
                'total': dext_score.get('total', 0),
                'upvotes': votes.get('upvotes', 0),
                'downvotes': votes.get('downvotes', 0)
            }
        
        # Process comprehensive metrics info
        if analysis['metrics'] and analysis['metrics'].get('statusCode') == 200:
            metrics_data = analysis['metrics'].get('data', {})
            
            result['data']['metrics'] = {
                'liquidity_usd': metrics_data.get('liquidity_usd', 0),
                'volume_24h_usd': metrics_data.get('volume_24h_usd', 0),
                'volume_1h_usd': metrics_data.get('volume_1h_usd', 0),
                'volume_6h_usd': metrics_data.get('volume_6h_usd', 0),
                'mcap': metrics_data.get('mcap', 0),
                'fdv': metrics_data.get('fdv', 0),
                'circulating_supply': metrics_data.get('circulating_supply', 0),
                'total_supply': metrics_data.get('total_supply', 0),
                'holders_count': metrics_data.get('holders_count', 0),
                'transactions': metrics_data.get('transactions', 0),
                'pool_address': metrics_data.get('pool_address', ''),
                'dex_info': metrics_data.get('dex_info', {})
            }
        
        # Process audit info
        if analysis['audit'] and analysis['audit'].get('statusCode') == 200:
            audit_data = analysis['audit'].get('data', {})
            
            result['data']['audit'] = {
                'is_open_source': audit_data.get('is_open_source', 'unknown'),
                'is_honeypot': audit_data.get('is_honeypot', 'unknown'),
                'is_mintable': audit_data.get('is_mintable', 'unknown'),
                'is_proxy': audit_data.get('is_proxy', 'unknown'),
                'slippage_modifiable': audit_data.get('slippage_modifiable', 'unknown'),
                'is_blacklisted': audit_data.get('is_blacklisted', 'unknown'),
                'is_contract_renounced': audit_data.get('is_contract_renounced', 'unknown'),
                'is_potentially_scam': audit_data.get('is_potentially_scam', 'unknown'),
                'buy_tax': {
                    'min': audit_data.get('buy_tax', {}).get('min') or 0,
                    'max': audit_data.get('buy_tax', {}).get('max') or 0,
                    'status': audit_data.get('buy_tax', {}).get('status', 'unknown')
                },
                'sell_tax': {
                    'min': audit_data.get('sell_tax', {}).get('min') or 0,
                    'max': audit_data.get('sell_tax', {}).get('max') or 0,
                    'status': audit_data.get('sell_tax', {}).get('status', 'unknown')
                },
                'updated_at': audit_data.get('updated_at', '')
            }
        
        # Process tax analysis info
        if analysis['tax_analysis'] and analysis['tax_analysis'].get('statusCode') == 200:
            tax_data = analysis['tax_analysis'].get('data', {})
            
            buy_tax_info = tax_data.get('buy_tax_info', {})
            sell_tax_info = tax_data.get('sell_tax_info', {})
            
            result['data']['tax_analysis'] = {
                'buy_tax_info': {
                    'min_percent': buy_tax_info.get('min_percent') or 0,
                    'max_percent': buy_tax_info.get('max_percent') or 0,
                    'status': buy_tax_info.get('status', 'unknown'),
                    'assessment': buy_tax_info.get('assessment', '')
                },
                'sell_tax_info': {
                    'min_percent': sell_tax_info.get('min_percent') or 0,
                    'max_percent': sell_tax_info.get('max_percent') or 0,
                    'status': sell_tax_info.get('status', 'unknown'),
                    'assessment': sell_tax_info.get('assessment', '')
                },
                'overall_assessment': tax_data.get('overall_assessment', ''),
                'is_honeypot': tax_data.get('is_honeypot', 'unknown'),
                'slippage_modifiable': tax_data.get('slippage_modifiable', 'unknown'),
                'contract_renounced': tax_data.get('contract_renounced', 'unknown')
            }
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'tokenAddress': token_address
        }), 500

@api.route('/analyzer/start', methods=['POST'])
def start_analyzer():
    """Start the background token analyzer"""
    try:
        analyzer.start_background_analysis()
        return jsonify({
            'success': True,
            'message': 'Token analyzer started',
            'status': analyzer.get_analysis_status()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/analyzer/stop', methods=['POST'])
def stop_analyzer():
    """Stop the background token analyzer"""
    try:
        analyzer.stop_background_analysis()
        return jsonify({
            'success': True,
            'message': 'Token analyzer stopped'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/analyzer/status', methods=['GET'])
def get_analyzer_status():
    """Get analyzer status"""
    return jsonify({
        'success': True,
        'data': analyzer.get_analysis_status()
    })

@api.route('/analyzer/suggestions', methods=['GET'])
def get_suggestions():
    """Get approved token suggestions"""
    return jsonify({
        'success': True,
        'data': {
            'approved': analyzer.get_approved_tokens(),
            'rejected': analyzer.get_rejected_tokens()
        }
    })

@api.route('/analyzer/criteria', methods=['GET'])
def get_criteria():
    """Get analysis criteria"""
    return jsonify({
        'success': True,
        'data': analyzer.criteria
    })

@api.route('/analyzer/criteria', methods=['PUT'])
def update_criteria():
    """Update analysis criteria"""
    try:
        new_criteria = request.get_json()
        analyzer.update_criteria(new_criteria)
        return jsonify({
            'success': True,
            'message': 'Criteria updated',
            'data': analyzer.criteria
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/performance/analysis', methods=['GET'])
def get_performance_analysis():
    """Get performance analysis of suggested tokens"""
    try:
        days_back = request.args.get('days', 7, type=int)
        days_back = min(max(days_back, 1), 30)  # Between 1 and 30 days
        
        analysis = performance_analyzer.analyze_all_suggestions(days_back)
        
        return jsonify({
            'success': True,
            'data': analysis
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/performance/token/<token_address>', methods=['GET'])
def get_token_performance(token_address):
    """Get detailed performance analysis for a specific token"""
    try:
        # Get the first suggestion for this token
        query = """
        SELECT token_address, token_name, token_symbol,
               price_usd as entry_price,
               liquidity_usd as entry_liquidity,
               volume_24h as entry_volume,
               analysis_score,
               suggested_at as entry_time
        FROM suggested_tokens 
        WHERE token_address = %s 
        ORDER BY suggested_at ASC 
        LIMIT 1
        """
        
        with performance_analyzer.token_repo.db.get_cursor() as cursor:
            cursor.execute(query, (token_address,))
            suggestion = cursor.fetchone()
        
        if not suggestion:
            return jsonify({
                'success': False,
                'error': 'Token not found in suggestions'
            }), 404
        
        analysis = performance_analyzer.analyze_token_performance(dict(suggestion))
        
        if not analysis:
            return jsonify({
                'success': False,
                'error': 'Unable to analyze token performance'
            }), 500
        
        return jsonify({
            'success': True,
            'data': analysis
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/analyzer/criteria-info', methods=['GET'])
def get_criteria_info():
    """Get detailed information about current criteria and improvements"""
    try:
        criteria = analyzer.criteria
        
        # Get rejection stats
        rejection_stats = getattr(analyzer, 'rejection_stats', {})
        
        # Categorize pump protection rejections
        pump_protection_stats = {
            'pump_warning': rejection_stats.get('pump_warning', 0),
            'high_volume_ratio': rejection_stats.get('high_volume_ratio', 0),
            'excessive_volume': rejection_stats.get('excessive_volume', 0),
            'bad_distribution': rejection_stats.get('bad_distribution', 0)
        }
        
        total_pump_protected = sum(pump_protection_stats.values())
        
        return jsonify({
            'success': True,
            'data': {
                'current_criteria': criteria,
                'key_improvements': {
                    'min_liquidity_increased': f"${criteria['min_liquidity']:,} (was $10,000)",
                    'min_dext_score_increased': f"{criteria['min_dext_score']} (was 70)",
                    'max_market_cap_reduced': f"${criteria['max_market_cap']:,} (was $20,000,000)",
                    'max_age_reduced': f"{criteria['max_age_hours']} hours (was 720 hours)"
                },
                'new_features': {
                    'volume_liquidity_ratio_protection': {
                        'max_ratio': criteria['max_volume_liquidity_ratio'],
                        'warning_threshold': criteria['warning_volume_liquidity_ratio'],
                        'optimal_range': f"{criteria['optimal_volume_liquidity_ratio_min']} - {criteria['optimal_volume_liquidity_ratio_max']}"
                    },
                    'pump_dump_protection': {
                        'max_initial_volume': f"${criteria['max_initial_volume_24h']:,}",
                        'bad_distribution_check': f">{criteria['max_holders_if_dropping']} holders + price drop"
                    }
                },
                'optimal_ranges': {
                    'liquidity': f"${criteria['optimal_liquidity_min']:,} - ${criteria['optimal_liquidity_max']:,}",
                    'volume_liquidity_ratio': f"{criteria['optimal_volume_liquidity_ratio_min']} - {criteria['optimal_volume_liquidity_ratio_max']}",
                    'market_cap': "< $1,000,000 preferred"
                },
                'pump_protection_stats': {
                    'total_protected': total_pump_protected,
                    'breakdown': pump_protection_stats,
                    'protection_rate': f"{(total_pump_protected / max(sum(rejection_stats.values()), 1) * 100):.1f}%" if rejection_stats else "0%"
                },
                'rejection_stats': rejection_stats
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/social/hot-pools', methods=['GET'])
def get_social_hot_pools():
    """Get hot pools with social metrics"""
    try:
        limit = request.args.get('limit', 50, type=int)
        limit = min(max(limit, 1), 100)  # Between 1 and 100
        
        pools = dextools.get_hot_pools_with_social(limit)
        
        # Sort by social score
        pools_with_social = [p for p in pools if p.get('socialMetrics', {}).get('score', 0) > 0]
        pools_with_social.sort(key=lambda x: x.get('socialMetrics', {}).get('score', 0), reverse=True)
        
        return jsonify({
            'success': True,
            'data': {
                'all_pools': pools,
                'top_social': pools_with_social[:10],
                'stats': {
                    'total_pools': len(pools),
                    'with_social': len(pools_with_social),
                    'avg_social_score': sum(p.get('socialMetrics', {}).get('score', 0) for p in pools_with_social) / len(pools_with_social) if pools_with_social else 0
                }
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/positions', methods=['GET'])
def get_positions():
    """Get current trading positions"""
    try:
        from trade.database.connection import TradeDatabase
        from trade.utils.solana_client import SolanaTrader
        from datetime import datetime, timedelta
        
        db = TradeDatabase()
        trader = SolanaTrader()
        
        # Get open positions
        with db.get_cursor() as cursor:
            cursor.execute("""
                SELECT 
                    t.id,
                    t.token_symbol,
                    t.token_address,
                    t.buy_price,
                    t.buy_amount,
                    t.buy_time,
                    t.token_decimals,
                    pm.current_price,
                    pm.price_change_percentage,
                    pm.monitored_at
                FROM trades t
                LEFT JOIN LATERAL (
                    SELECT * FROM price_monitoring 
                    WHERE trade_id = t.id 
                    ORDER BY monitored_at DESC 
                    LIMIT 1
                ) pm ON true
                WHERE t.status = 'OPEN'
                ORDER BY t.buy_time DESC
            """)
            
            trades = cursor.fetchall()
            
        positions = []
        for trade in trades:
            # Calculate time held
            buy_time = trade['buy_time']
            time_held = datetime.now() - buy_time
            hours = int(time_held.total_seconds() / 3600)
            minutes = int((time_held.total_seconds() % 3600) / 60)
            
            # Get real balance from wallet
            real_balance = trader.get_token_balance(trade['token_address'])
            
            # Use buy_amount as fallback if real balance is 0 or None
            if not real_balance or real_balance == 0:
                real_balance = float(trade['buy_amount']) if trade['buy_amount'] else 0
            
            # Calculate P&L
            current_price = trade['current_price'] or trade['buy_price']
            price_change = trade['price_change_percentage'] or 0
            
            # Calculate investment and current value
            investment = float(trade['buy_price']) * float(real_balance)
            current_value = float(current_price) * float(real_balance)
            pnl_amount = current_value - investment
            pnl_percentage = ((current_value - investment) / investment * 100) if investment > 0 else 0
            
            # Status emoji based on P&L
            if pnl_percentage >= 20:
                status_emoji = "üöÄ"
            elif pnl_percentage >= 10:
                status_emoji = "üü¢"
            elif pnl_percentage >= 0:
                status_emoji = "üîµ"
            elif pnl_percentage >= -5:
                status_emoji = "üü†"
            else:
                status_emoji = "üî¥"
            
            position = {
                'id': trade['id'],
                'symbol': trade['token_symbol'],
                'address': trade['token_address'],
                'status_emoji': status_emoji,
                'buy_price': float(trade['buy_price']),
                'current_price': float(current_price),
                'price_change_24h': price_change,
                'tokens_amount': float(real_balance),
                'time_held_hours': hours,
                'time_held_minutes': minutes,
                'time_held_display': f"{hours}h {minutes}m",
                'investment_usd': investment,
                'current_value_usd': current_value,
                'pnl_amount': pnl_amount,
                'pnl_percentage': pnl_percentage,
                'decimals': trade['token_decimals'] or 9,
                'last_updated': trade['monitored_at'].isoformat() if trade['monitored_at'] else None
            }
            
            positions.append(position)
        
        # Calculate totals
        total_investment = sum(p['investment_usd'] for p in positions)
        total_current_value = sum(p['current_value_usd'] for p in positions)
        total_pnl = total_current_value - total_investment
        total_pnl_pct = (total_pnl / total_investment * 100) if total_investment > 0 else 0
        
        # Count profitable positions
        profitable_positions = len([p for p in positions if p['pnl_percentage'] > 0])
        
        return jsonify({
            'success': True,
            'data': {
                'positions': positions,
                'summary': {
                    'total_positions': len(positions),
                    'profitable_positions': profitable_positions,
                    'win_rate_pct': (profitable_positions / len(positions) * 100) if positions else 0,
                    'total_investment': total_investment,
                    'total_current_value': total_current_value,
                    'total_pnl_amount': total_pnl,
                    'total_pnl_percentage': total_pnl_pct
                }
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/trades/statistics', methods=['GET'])
def get_trading_statistics():
    """Get comprehensive trading performance statistics"""
    try:
        from trade.database.connection import TradeDatabase
        from datetime import datetime, timedelta
        
        db = TradeDatabase()
        
        with db.get_cursor() as cursor:
            # Get overall trading statistics
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_trades,
                    COUNT(CASE WHEN status = 'OPEN' THEN 1 END) as open_trades,
                    COUNT(CASE WHEN status = 'CLOSED' THEN 1 END) as closed_trades,
                    COUNT(CASE WHEN profit_loss_percentage > 0 THEN 1 END) as winning_trades,
                    COUNT(CASE WHEN profit_loss_percentage < 0 THEN 1 END) as losing_trades,
                    AVG(CASE WHEN status = 'CLOSED' AND profit_loss_percentage > 0 THEN profit_loss_amount END) as avg_win_amount,
                    AVG(CASE WHEN status = 'CLOSED' AND profit_loss_percentage < 0 THEN profit_loss_amount END) as avg_loss_amount,
                    AVG(CASE WHEN status = 'CLOSED' THEN profit_loss_percentage END) as avg_profit_loss_percentage,
                    SUM(CASE WHEN status = 'CLOSED' THEN profit_loss_amount END) as total_profit_loss,
                    MAX(CASE WHEN status = 'CLOSED' THEN profit_loss_amount END) as max_win,
                    MIN(CASE WHEN status = 'CLOSED' THEN profit_loss_amount END) as max_loss
                FROM trades
            """)
            
            stats = cursor.fetchone()
            
            # Calculate win rate
            closed_trades = stats['closed_trades'] or 0
            winning_trades = stats['winning_trades'] or 0
            win_rate = (winning_trades / closed_trades * 100) if closed_trades > 0 else 0
            
            # Calculate profit factor
            total_wins = abs(float(stats['avg_win_amount'] or 0)) * winning_trades
            total_losses = abs(float(stats['avg_loss_amount'] or 0)) * (closed_trades - winning_trades)
            profit_factor = (total_wins / total_losses) if total_losses > 0 else 0
            
            # Get daily P&L for last 7 days
            cursor.execute("""
                SELECT 
                    DATE(sell_time) as trade_date,
                    SUM(profit_loss_amount) as daily_pnl,
                    COUNT(*) as trades_count
                FROM trades 
                WHERE status = 'CLOSED' 
                    AND sell_time >= %s 
                GROUP BY DATE(sell_time)
                ORDER BY trade_date DESC
                LIMIT 7
            """, (datetime.now() - timedelta(days=7),))
            
            daily_pnl_data = cursor.fetchall()
            
            # Format daily P&L for chart
            days_of_week = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
            daily_pnl = []
            
            # Fill last 7 days with data or 0
            for i in range(7):
                date = datetime.now().date() - timedelta(days=6-i)
                day_name = days_of_week[date.weekday()]
                
                # Find data for this date
                day_data = next((row for row in daily_pnl_data if row['trade_date'] == date), None)
                pnl = float(day_data['daily_pnl']) if day_data and day_data['daily_pnl'] else 0
                
                daily_pnl.append({
                    'day': day_name,
                    'pnl': pnl
                })
            
            # Get top performers (best closed trades)
            cursor.execute("""
                SELECT 
                    token_symbol,
                    profit_loss_amount,
                    profit_loss_percentage,
                    sell_time
                FROM trades 
                WHERE status = 'CLOSED' 
                    AND profit_loss_percentage > 0
                ORDER BY profit_loss_percentage DESC
                LIMIT 3
            """)
            
            top_performers = [
                {
                    'symbol': row['token_symbol'] or 'Unknown',
                    'pnl': float(row['profit_loss_amount'] or 0),
                    'percentage': float(row['profit_loss_percentage'] or 0)
                }
                for row in cursor.fetchall()
            ]
            
            # Get recent trading alerts (recent profitable/loss trades)
            cursor.execute("""
                SELECT 
                    token_symbol,
                    profit_loss_percentage,
                    sell_reason,
                    sell_time
                FROM trades 
                WHERE status = 'CLOSED' 
                    AND sell_time >= %s
                ORDER BY sell_time DESC
                LIMIT 5
            """, (datetime.now() - timedelta(hours=24),))
            
            recent_trades = cursor.fetchall()
            alerts = []
            
            for trade in recent_trades:
                pnl_pct = float(trade['profit_loss_percentage'] or 0)
                symbol = trade['token_symbol'] or 'Unknown'
                
                if pnl_pct >= 50:
                    alerts.append({
                        'type': 'profit',
                        'message': f'{symbol} hit +{pnl_pct:.1f}% target',
                        'time': '2m ago'  # Simplified for now
                    })
                elif pnl_pct <= -10:
                    alerts.append({
                        'type': 'warning', 
                        'message': f'{symbol} triggered stop loss ({pnl_pct:.1f}%)',
                        'time': '15m ago'
                    })
            
            # Calculate advanced metrics
            max_drawdown = float(stats['max_loss'] or 0)
            sharpe_ratio = 1.8  # Simplified calculation for now
            
            return jsonify({
                'success': True,
                'data': {
                    # Basic performance metrics
                    'totalPnL': float(stats['total_profit_loss'] or 0),
                    'totalPnLPercentage': float(stats['avg_profit_loss_percentage'] or 0),
                    'winRate': win_rate,
                    'totalTrades': stats['total_trades'] or 0,
                    'winningTrades': winning_trades,
                    'losingTrades': (closed_trades - winning_trades),
                    'avgWin': float(stats['avg_win_amount'] or 0),
                    'avgLoss': float(stats['avg_loss_amount'] or 0),
                    'profitFactor': profit_factor,
                    'sharpeRatio': sharpe_ratio,
                    'maxDrawdown': max_drawdown,
                    
                    # Charts and trends
                    'dailyPnL': daily_pnl,
                    'topPerformers': top_performers,
                    'alerts': alerts,
                    
                    # Summary for other components
                    'summary': {
                        'total_positions': stats['open_trades'] or 0,
                        'profitable_positions': winning_trades,
                        'win_rate_pct': win_rate,
                        'total_pnl_amount': float(stats['total_profit_loss'] or 0),
                        'total_pnl_percentage': float(stats['avg_profit_loss_percentage'] or 0)
                    }
                }
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/market-intelligence/<token_address>', methods=['GET'])
def get_market_intelligence(token_address):
    """Get comprehensive real-time market intelligence data for a token"""
    try:
        from backend.services.dextools_service import DEXToolsService
        from datetime import datetime, timedelta
        import time
        import concurrent.futures
        import threading
        
        dextools = DEXToolsService()
        
        # Get comprehensive token analysis with timeout and parallel execution
        print(f"üìä Getting market intelligence for: {token_address}")
        
        # Use ThreadPoolExecutor to make parallel API calls with individual timeouts
        def get_token_info_safe():
            try:
                return dextools.get_token_info(token_address)
            except Exception as e:
                print(f"‚ùå Token info failed: {e}")
                return None
        
        def get_token_price_safe():
            try:
                return dextools.get_token_price(token_address)
            except Exception as e:
                print(f"‚ùå Token price failed: {e}")
                return None
        
        def get_token_metrics_safe():
            try:
                # Skip heavy metrics call for now to avoid timeout
                return None
            except Exception as e:
                print(f"‚ùå Token metrics failed: {e}")
                return None
        
        def get_token_score_safe():
            try:
                return dextools.get_token_score(token_address)
            except Exception as e:
                print(f"‚ùå Token score failed: {e}")
                return None
        
        # Execute API calls in parallel with 10 second timeout each
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            # Submit all tasks
            info_future = executor.submit(get_token_info_safe)
            price_future = executor.submit(get_token_price_safe)
            metrics_future = executor.submit(get_token_metrics_safe)
            score_future = executor.submit(get_token_score_safe)
            
            # Get results with timeout
            try:
                token_info = info_future.result(timeout=8)
            except concurrent.futures.TimeoutError:
                print("‚ùå Token info timeout")
                token_info = None
                
            try:
                price_data = price_future.result(timeout=8)
            except concurrent.futures.TimeoutError:
                print("‚ùå Token price timeout")
                price_data = None
                
            try:
                token_metrics = metrics_future.result(timeout=8)
            except concurrent.futures.TimeoutError:
                print("‚ùå Token metrics timeout")
                token_metrics = None
                
            try:
                token_score = score_future.result(timeout=8)
            except concurrent.futures.TimeoutError:
                print("‚ùå Token score timeout")
                token_score = None
        
        # Parse data safely with fallbacks
        info_data = token_info.get('data', {}) if token_info and token_info.get('success') else {}
        price_info = price_data.get('data', {}) if price_data and price_data.get('success') else {}
        metrics_data = token_metrics.get('data', {}) if token_metrics and token_metrics.get('success') else {}
        score_data = token_score.get('data', {}) if token_score and token_score.get('success') else {}
        
        print(f"üìä Data status - Info: {'‚úÖ' if info_data else '‚ùå'}, Price: {'‚úÖ' if price_info else '‚ùå'}, Metrics: {'‚úÖ' if metrics_data else '‚ùå'}, Score: {'‚úÖ' if score_data else '‚ùå'}")
        
        # If we have no data at all, return basic structure
        if not info_data and not price_info:
            print("‚ùå No data available, returning fallback")
            return jsonify({
                'success': True,
                'data': {
                    'token_address': token_address,
                    'timestamp': datetime.now().isoformat(),
                    'price': 0,
                    'priceChange24h': 0,
                    'volume24h': 0,
                    'marketCap': 0,
                    'liquidity': 0,
                    'holders': 0,
                    'fdv': 0,
                    'priceHistory': [{'time': i, 'price': 0} for i in range(24)],
                    'volumeHistory': [{'day': i, 'volume': 0} for i in range(7)],
                    'technicalAnalysis': {
                        'rsi': {'value': 50, 'status': 'neutral'},
                        'macd': {'value': 0, 'status': 'neutral'},
                        'volumeProfile': {'level': 'Low', 'status': 'neutral'}
                    },
                    'priceLevels': {
                        'resistance': 0,
                        'support': 0,
                        'resistanceDistance': 0,
                        'supportDistance': 0
                    },
                    'socialInfo': {
                        'website': '',
                        'twitter': '',
                        'telegram': '',
                        'discord': '',
                        'hasWebsite': False,
                        'hasTwitter': False,
                        'hasTelegram': False
                    },
                    'signals': [{
                        'type': 'INFO',
                        'icon': '‚ö†Ô∏è',
                        'message': 'Unable to fetch real-time data. Please try again later.',
                        'time': 'Now',
                        'strength': 'warning'
                    }],
                    'security': {'score': 0, 'level': 'Unknown'},
                    'poolInfo': {'address': '', 'dex': 'Unknown'},
                    'trends': {
                        'volume': 'neutral',
                        'liquidity': 'neutral',
                        'holders': 'neutral'
                    }
                }
            })
        
        # Extract social info
        social_info = info_data.get('socialInfo', {})
        
        # Calculate technical indicators (simplified) with fallbacks
        current_price = float(price_info.get('price', 0.000001))  # Small default to avoid division by zero
        price_variation = float(price_info.get('variation', 0))
        
        # Generate mock price history based on current price (for now)
        price_history = []
        base_price = current_price
        for i in range(24):
            variation = (price_variation / 100) * (1 - (i / 24))  # Gradual change over time
            price_point = base_price * (1 + variation * 0.1)  # Small variations
            price_history.append({
                'time': i,
                'price': price_point,
                'timestamp': datetime.now() - timedelta(hours=23-i)
            })
        
        # Generate volume history based on real volume data
        volume_24h = float(metrics_data.get('volume_24h_usd', 0))
        volume_history = []
        for i in range(7):
            # Vary volume by ¬±30% for each day
            daily_variation = (i - 3) * 0.1  # -0.3 to +0.3 variation
            daily_volume = volume_24h * (1 + daily_variation)
            volume_history.append({
                'day': i,
                'volume': max(0, daily_volume),
                'date': datetime.now() - timedelta(days=6-i)
            })
        
        # Calculate technical analysis values
        rsi = min(100, max(0, 50 + (price_variation * 2)))  # RSI based on price variation
        rsi_status = 'bullish' if rsi > 70 else 'bearish' if rsi < 30 else 'neutral'
        
        macd_value = price_variation / 100 * current_price * 0.01  # Small MACD value
        macd_status = 'bullish' if macd_value > 0 else 'bearish'
        
        volume_profile = 'High' if volume_24h > 100000 else 'Medium' if volume_24h > 10000 else 'Low'
        volume_status = 'bullish' if volume_24h > 50000 else 'neutral'
        
        # Calculate support and resistance levels
        resistance_level = current_price * 1.15  # 15% above current
        support_level = current_price * 0.85     # 15% below current
        
        # Generate trading signals based on real data
        signals = []
        
        # Volume surge signal
        if volume_24h > 500000:
            signals.append({
                'type': 'STRONG_BUY',
                'icon': 'üöÄ',
                'message': f'Volume surge detected (${volume_24h:,.0f}). Strong momentum.',
                'time': '2m ago',
                'strength': 'strong-buy'
            })
        elif volume_24h > 100000:
            signals.append({
                'type': 'BUY',
                'icon': 'üìà', 
                'message': f'Increased volume detected (${volume_24h:,.0f}).',
                'time': '5m ago',
                'strength': 'buy'
            })
        
        # Price movement signal
        if price_variation > 20:
            signals.append({
                'type': 'PROFIT_TAKING',
                'icon': 'üí∞',
                'message': f'Strong pump detected (+{price_variation:.1f}%). Consider taking profits.',
                'time': '1m ago',
                'strength': 'warning'
            })
        elif price_variation < -15:
            signals.append({
                'type': 'DIP_BUY',
                'icon': 'üõí',
                'message': f'Significant dip ({price_variation:.1f}%). Potential buy opportunity.',
                'time': '3m ago',
                'strength': 'info'
            })
        
        # Liquidity signal
        liquidity_usd = float(metrics_data.get('liquidity_usd', 0))
        if liquidity_usd > 1000000:
            signals.append({
                'type': 'INFO',
                'icon': 'üíß',
                'message': f'High liquidity pool (${liquidity_usd:,.0f}). Good for large trades.',
                'time': '10m ago',
                'strength': 'info'
            })
        elif liquidity_usd < 50000:
            signals.append({
                'type': 'CAUTION',
                'icon': '‚ö†Ô∏è',
                'message': f'Low liquidity (${liquidity_usd:,.0f}). High slippage risk.',
                'time': '5m ago',
                'strength': 'warning'
            })
        
        # Default signal if no specific conditions
        if not signals:
            signals.append({
                'type': 'INFO',
                'icon': 'üí°',
                'message': 'Market monitoring active. No significant signals detected.',
                'time': '1m ago',
                'strength': 'info'
            })
        
        return jsonify({
            'success': True,
            'data': {
                'token_address': token_address,
                'timestamp': datetime.now().isoformat(),
                
                # Basic price data
                'price': current_price,
                'priceChange24h': price_variation,
                'volume24h': volume_24h,
                'marketCap': float(metrics_data.get('mcap', 0)),
                'liquidity': liquidity_usd,
                'holders': int(metrics_data.get('holders_count', 0)),
                'fdv': float(metrics_data.get('fdv', 0)),
                
                # Charts data
                'priceHistory': price_history,
                'volumeHistory': volume_history,
                
                # Technical analysis
                'technicalAnalysis': {
                    'rsi': {
                        'value': round(rsi, 1),
                        'status': rsi_status
                    },
                    'macd': {
                        'value': round(macd_value, 6),
                        'status': macd_status
                    },
                    'volumeProfile': {
                        'level': volume_profile,
                        'status': volume_status
                    }
                },
                
                # Price levels
                'priceLevels': {
                    'resistance': resistance_level,
                    'support': support_level,
                    'resistanceDistance': ((resistance_level - current_price) / current_price * 100),
                    'supportDistance': ((support_level - current_price) / current_price * 100)
                },
                
                # Social info
                'socialInfo': {
                    'website': social_info.get('website', ''),
                    'twitter': social_info.get('twitter', ''),
                    'telegram': social_info.get('telegram', ''),
                    'discord': social_info.get('discord', ''),
                    'hasWebsite': bool(social_info.get('website')),
                    'hasTwitter': bool(social_info.get('twitter')),
                    'hasTelegram': bool(social_info.get('telegram'))
                },
                
                # Trading signals
                'signals': signals[:3],  # Limit to 3 most relevant signals
                
                # Token score/security
                'security': {
                    'score': float(score_data.get('dextScore', 0)) if score_data else 0,
                    'level': 'High' if score_data and float(score_data.get('dextScore', 0)) > 80 else 'Medium' if score_data and float(score_data.get('dextScore', 0)) > 50 else 'Low'
                },
                
                # Pool info
                'poolInfo': {
                    'address': metrics_data.get('pool_address', ''),
                    'dex': metrics_data.get('dex_info', {}).get('name', 'Unknown')
                },
                
                # Metrics trends (simplified)
                'trends': {
                    'volume': 'positive' if price_variation > 0 else 'negative',
                    'liquidity': 'positive' if liquidity_usd > 100000 else 'neutral',
                    'holders': 'positive' if metrics_data.get('holders_count', 0) > 100 else 'neutral'
                }
            }
        })
        
    except Exception as e:
        print(f"‚ùå Error getting market intelligence: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/market-intelligence-fast/<token_address>', methods=['GET'])
def get_market_intelligence_fast(token_address):
    """Get fast market intelligence data for a token (basic data only)"""
    try:
        from backend.services.dextools_service import DEXToolsService
        from datetime import datetime, timedelta
        
        dextools = DEXToolsService()
        
        print(f"üöÄ Getting FAST market intelligence for: {token_address}")
        
        # Only get essential data quickly
        try:
            price_data = dextools.get_token_price(token_address)
            price_info = price_data.get('data', {}) if price_data and price_data.get('success') else {}
        except Exception as e:
            print(f"‚ùå Fast price failed: {e}")
            price_info = {}
        
        # Get basic values with fallbacks
        current_price = float(price_info.get('price', 0.000001))
        price_variation = float(price_info.get('variation', 0))
        
        # Generate basic price history
        price_history = []
        base_price = current_price
        for i in range(24):
            variation = (price_variation / 100) * (1 - (i / 24))
            price_point = base_price * (1 + variation * 0.1)
            price_history.append({
                'time': i,
                'price': price_point,
                'timestamp': datetime.now() - timedelta(hours=23-i)
            })
        
        # Generate basic volume history
        estimated_volume = abs(price_variation) * 10000  # Estimate based on price movement
        volume_history = []
        for i in range(7):
            daily_variation = (i - 3) * 0.1
            daily_volume = estimated_volume * (1 + daily_variation)
            volume_history.append({
                'day': i,
                'volume': max(0, daily_volume),
                'date': datetime.now() - timedelta(days=6-i)
            })
        
        # Simple technical analysis
        rsi = min(100, max(0, 50 + (price_variation * 2)))
        rsi_status = 'bullish' if rsi > 70 else 'bearish' if rsi < 30 else 'neutral'
        
        macd_value = price_variation / 100 * current_price * 0.01
        macd_status = 'bullish' if macd_value > 0 else 'bearish'
        
        # Basic resistance/support
        resistance_level = current_price * 1.15
        support_level = current_price * 0.85
        
        # Generate signals based on price movement
        signals = []
        if price_variation > 20:
            signals.append({
                'type': 'STRONG_MOVE',
                'icon': 'üöÄ',
                'message': f'Strong pump detected (+{price_variation:.1f}%). Monitor closely.',
                'time': '1m ago',
                'strength': 'strong-buy'
            })
        elif price_variation < -15:
            signals.append({
                'type': 'DIP_ALERT',
                'icon': 'üõí',
                'message': f'Significant dip ({price_variation:.1f}%). Potential opportunity.',
                'time': '2m ago',
                'strength': 'info'
            })
        else:
            signals.append({
                'type': 'MONITORING',
                'icon': 'üëÅÔ∏è',
                'message': 'Price monitoring active. Normal market conditions.',
                'time': 'Now',
                'strength': 'info'
            })
        
        return jsonify({
            'success': True,
            'data': {
                'token_address': token_address,
                'timestamp': datetime.now().isoformat(),
                'price': current_price,
                'priceChange24h': price_variation,
                'volume24h': estimated_volume,
                'marketCap': 0,  # Will be populated later
                'liquidity': 0,  # Will be populated later
                'holders': 0,   # Will be populated later
                'fdv': 0,       # Will be populated later
                'priceHistory': price_history,
                'volumeHistory': volume_history,
                'technicalAnalysis': {
                    'rsi': {'value': round(rsi, 1), 'status': rsi_status},
                    'macd': {'value': round(macd_value, 6), 'status': macd_status},
                    'volumeProfile': {'level': 'Medium', 'status': 'neutral'}
                },
                'priceLevels': {
                    'resistance': resistance_level,
                    'support': support_level,
                    'resistanceDistance': ((resistance_level - current_price) / current_price * 100),
                    'supportDistance': ((support_level - current_price) / current_price * 100)
                },
                'socialInfo': {
                    'website': '',
                    'twitter': '',
                    'telegram': '',
                    'discord': '',
                    'hasWebsite': False,
                    'hasTwitter': False,
                    'hasTelegram': False
                },
                'signals': signals,
                'security': {'score': 0, 'level': 'Unknown'},
                'poolInfo': {'address': '', 'dex': 'Unknown'},
                'trends': {
                    'volume': 'positive' if price_variation > 0 else 'negative',
                    'liquidity': 'neutral',
                    'holders': 'neutral'
                }
            }
        })
        
    except Exception as e:
        print(f"‚ùå Error getting fast market intelligence: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/market-intelligence/enhanced/<token_address>', methods=['GET'])
def get_market_intelligence_enhanced(token_address):
    """Get enhanced market intelligence data (heavy data for background loading)"""
    try:
        from backend.services.dextools_service import DEXToolsService
        import concurrent.futures
        
        dextools = DEXToolsService()
        
        print(f"üîç Getting ENHANCED market intelligence for: {token_address}")
        
        # Get enhanced data with timeouts
        def get_token_info_safe():
            try:
                return dextools.get_token_info(token_address)
            except:
                return None
        
        def get_token_score_safe():
            try:
                return dextools.get_token_score(token_address)
            except:
                return None
        
        # Execute in parallel with short timeout
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            info_future = executor.submit(get_token_info_safe)
            score_future = executor.submit(get_token_score_safe)
            
            try:
                token_info = info_future.result(timeout=10)
            except:
                token_info = None
                
            try:
                token_score = score_future.result(timeout=10)
            except:
                token_score = None
        
        # Parse enhanced data
        info_data = token_info.get('data', {}) if token_info and token_info.get('success') else {}
        score_data = token_score.get('data', {}) if token_score and token_score.get('success') else {}
        
        social_info = info_data.get('socialInfo', {})
        
        return jsonify({
            'success': True,
            'data': {
                'token_address': token_address,
                'marketCap': float(info_data.get('mcap', 0)),
                'holders': int(info_data.get('holders', 0)) if str(info_data.get('holders', 0)).isdigit() else 0,
                'fdv': float(info_data.get('fdv', 0)),
                'socialInfo': {
                    'website': social_info.get('website', ''),
                    'twitter': social_info.get('twitter', ''),
                    'telegram': social_info.get('telegram', ''),
                    'discord': social_info.get('discord', ''),
                    'hasWebsite': bool(social_info.get('website')),
                    'hasTwitter': bool(social_info.get('twitter')),
                    'hasTelegram': bool(social_info.get('telegram'))
                },
                'security': {
                    'score': float(score_data.get('dextScore', 0)) if score_data else 0,
                    'level': 'High' if score_data and float(score_data.get('dextScore', 0)) > 80 else 'Medium' if score_data and float(score_data.get('dextScore', 0)) > 50 else 'Low'
                }
            }
        })
        
    except Exception as e:
        print(f"‚ùå Error getting enhanced market intelligence: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/market-intelligence/metrics/<token_address>', methods=['GET'])
def get_market_intelligence_metrics(token_address):
    """Get metrics data (volume, liquidity) for background loading"""
    try:
        from backend.services.dextools_service import DEXToolsService
        
        dextools = DEXToolsService()
        
        print(f"üìä Getting METRICS for: {token_address}")
        
        # Get metrics data with timeout
        try:
            token_metrics = dextools.get_token_metrics(token_address)
            metrics_data = token_metrics.get('data', {}) if token_metrics and token_metrics.get('success') else {}
        except Exception as e:
            print(f"‚ùå Metrics failed: {e}")
            metrics_data = {}
        
        volume_24h = float(metrics_data.get('volume_24h_usd', 0))
        liquidity_usd = float(metrics_data.get('liquidity_usd', 0))
        
        return jsonify({
            'success': True,
            'data': {
                'token_address': token_address,
                'volume24h': volume_24h,
                'liquidity': liquidity_usd,
                'volume_1h_usd': float(metrics_data.get('volume_1h_usd', 0)),
                'volume_6h_usd': float(metrics_data.get('volume_6h_usd', 0)),
                'poolInfo': {
                    'address': metrics_data.get('pool_address', ''),
                    'dex': metrics_data.get('dex_info', {}).get('name', 'Unknown')
                },
                'trends': {
                    'volume': 'positive' if volume_24h > 100000 else 'neutral',
                    'liquidity': 'positive' if liquidity_usd > 100000 else 'neutral'
                }
            }
        })
        
    except Exception as e:
        print(f"‚ùå Error getting metrics: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'service': 'Solana Hot Pools API',
        'analyzer_running': analyzer.is_running,
        'timestamp': time.time()
    })